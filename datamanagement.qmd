# KDV Data Management

Most of our projects have complicated data structures with multiple sources, multiple scale (of space and time), and multiple variables.  Raw data may be delivered by variable, by source, or by some other organizing factor.  Every project requires a data management strategy that imprts the data from these diverse sources into an organized framework.  This framework should have well-defined naming conventions and facilitate flexible subsetting and merging of data as needed across sources and scales.  Most of our projects involve an element of incremental discovery, so refactoring at least once through the lifespan of a project is not uncommon.  Establishing well-defined "gateways" for data management is helpful (e.g., data prep, merge, qaqc, analysis) - where the data structure exiting a prior stage is structured to meet requirements of the following stage.

## Raw Data

Raw data received form clients should be saved within the KDV dropbox **A_Data/NewProject/[...]** exactly as-is.  Any supporting documentation or correspondance regarding the raw data should be saved in the same raw data folder as the data itself.  Only in very rare circumstances would raw data be edited outside an R script.  If this is required, a **README_[...]_kdv_edits.txt** file should be added to the raw data folder.  If possible, the edits should be made to a copy of the raw data.  The goal is to always have an original unmodified copy of the raw data along with all associated explanatory correspondence located in the same folder.

## Data Prep

The data prep step brings raw data from Dropbox into the associated R project environment (usually on our local systems).  A series of **prep_[...].rmd** files import, inspect, document and summarize each raw data file and then export the data into the agreed standard file structure following the agreed naming conventions.  A series of tests should be applied prior to saving to ensure all data meet the agreed standards.






